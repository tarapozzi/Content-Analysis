#Install packages
install.packages("readtext")
install.packages("quanteda")
install.packages("tidytext")
install.packages("topicmodels")
install.packages("tidyverse")
install.packages("ggplot2")
#load packages
library(readtext)
library(quanteda)
library(tidytext)
library(topicmodels)
library(ggplot2)
library(tidyverse)
iwf_path <- "/Users/tarapozzi/Desktop/contentintro/IWF"
cbd_path <- "/Users/tarapozzi/Desktop/contentintro/CBD"
#read pdfs
iwf_pdfs <- list.files(path = iwf_path, pattern = 'pdf$',  full.names = TRUE)
iwf_texts <- readtext(iwf_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
cbd_pdfs <- list.files(path = cbd_path, pattern = 'pdf$',  full.names = TRUE)
cbd_texts <- readtext(cbd_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
#convert to corpus
iwf_corpus  <- corpus(iwf_texts)
cbd_corpus <- corpus(cbd_texts)
?corpus
install.packages("SnowballC")
install.packages("spacyr")
library(spacyr)
#read in pdfs
#folder where files are located
iwf_path <- "/Users/tarapozzi/Desktop/contentintro/IWF"
cbd_path <- "/Users/tarapozzi/Desktop/contentintro/CBD"
#read pdfs
iwf_pdfs <- list.files(path = iwf_path, pattern = 'pdf$',  full.names = TRUE)
iwf_texts <- readtext(iwf_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
cbd_pdfs <- list.files(path = cbd_path, pattern = 'pdf$',  full.names = TRUE)
cbd_texts <- readtext(cbd_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
#convert to corpus
iwf_corpus  <- corpus(iwf_texts)
cbd_corpus <- corpus(cbd_texts)
library(spacyr)
library(tidyverse)
library(spacyr)
#read in pdfs
#folder where files are located
iwf_path <- "/Users/tarapozzi/Desktop/contentintro/IWF"
cbd_path <- "/Users/tarapozzi/Desktop/contentintro/CBD"
#read pdfs
iwf_pdfs <- list.files(path = iwf_path, pattern = 'pdf$',  full.names = TRUE)
iwf_texts <- readtext(iwf_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
cbd_pdfs <- list.files(path = cbd_path, pattern = 'pdf$',  full.names = TRUE)
cbd_texts <- readtext(cbd_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
#convert to corpus
iwf_corpus  <- corpus(iwf_texts)
cbd_corpus <- corpus(cbd_texts)
library(readtext)
library(quanteda)
library(tidytext)
library(topicmodels)
library(ggplot2)
library(tidyverse)
library(spacyr)
#read in pdfs
#folder where files are located
iwf_path <- "/Users/tarapozzi/Desktop/contentintro/IWF"
cbd_path <- "/Users/tarapozzi/Desktop/contentintro/CBD"
#read pdfs
iwf_pdfs <- list.files(path = iwf_path, pattern = 'pdf$',  full.names = TRUE)
iwf_texts <- readtext(iwf_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
cbd_pdfs <- list.files(path = cbd_path, pattern = 'pdf$',  full.names = TRUE)
cbd_texts <- readtext(cbd_pdfs,
sep = "_",
docvarnames = c("First_author", "Year"))
#convert to corpus
iwf_corpus  <- corpus(iwf_texts)
cbd_corpus <- corpus(cbd_texts)
# Some stats about the news releases
summary(iwf_corpus)
summary(cbd_corpus)
metadoc(iwf_corpus, 'language') <- "english"
metadoc(cbd_corpus, 'language') <- "english"
#buidliing a document frequency matrix (DFM)
iwf_DFM <- dfm(iwf_corpus, tolower = TRUE, stem = FALSE,
remove = c("et", "al", "fig", "table", "ml", "http",
stopwords("smart")),
remove_punct = TRUE, remove_numbers = TRUE)
cbd_DFM <- dfm(cbd_corpus, tolower = TRUE, stem = FALSE,
remove = c("et", "al", "fig", "table", "ml", "http",
stopwords("smart")),
remove_punct = TRUE, remove_numbers = TRUE)
#summarise the two DFM's
topfeatures(iwf_DFM, 20)
topfeatures(cbd_DFM, 20)
#visualize commonly used words
textplot_wordcloud(iwf_DFM, min.freq = 15, random.order=F,
rot.per = .10,
colors = RColorBrewer::brewer.pal(8,'Dark2'))
textplot_wordcloud(cbd_DFM, min.freq = 15, random.order=F,
rot.per = .10,
colors = RColorBrewer::brewer.pal(8,'Dark2'))
## Unsupervised classification of topics
iwf_topicmod <- convert(iwf_DFM, to="topicmodels")
iwf_lda <- LDA(iwf_topicmod, k=3)
iwf_topics <- tidy(iwf_lda, matrix="beta")
iwf_top_terms <- iwf_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
iwf_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
cbd_topicmod <- convert(cbd_DFM, to="topicmodels")
cbd_lda <- LDA(cbd_topicmod, k=3)
cbd_topics <- tidy(cbd_lda, matrix="beta")
cbd_top_terms <- cbd_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
cbd_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
#sentiment analysis
tidy(iwf_DFM) %>%
inner_join(get_sentiments("bing"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
tidy(cbd_DFM) %>%
inner_join(get_sentiments("bing"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
tidy(iwf_DFM) %>%
inner_join(get_sentiments("nrc"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
tidy(cbd_DFM) %>%
inner_join(get_sentiments("nrc"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
## Using additional words for context
iwf_bigrams <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
cbd_bigrams <- tidy(cbd_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
negation_words <- c("not", "no", "never", "without")
iwf_notwords <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, value, sort = TRUE)
cbd_notwords <- tidy(cbd_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, value, sort = TRUE)
iwf_notwords %>%
mutate(contribution = n * value) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * value, fill = n * value > 0)) +
geom_col(show.legend = FALSE) +
xlab("Words preceded by \"not\"") +
ylab("Sentiment value * number of occurrences") +
coord_flip()
cbd_notwords %>%
mutate(contribution = n * value) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * value, fill = n * value > 0)) +
geom_col(show.legend = FALSE) +
xlab("Words preceded by \"not\"") +
ylab("Sentiment value * number of occurrences") +
coord_flip()
tidy(iwf_DFM) %>%
inner_join(get_sentiments("nrc"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
install.packages("textdata")
library(textdata)
tidy(iwf_DFM) %>%
inner_join(get_sentiments("nrc"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
tidy(cbd_DFM) %>%
inner_join(get_sentiments("nrc"), by = c(term = "word")) %>%
count(sentiment, term, wt = count) %>%
ungroup() %>%
filter(n >= 5) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(term = reorder(term, n)) %>%
ggplot(aes(term, n, fill = sentiment)) +
geom_bar(stat = "identity") +
ylab("Contribution to sentiment") +
coord_flip()
iwf_bigrams <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
cbd_bigrams <- tidy(cbd_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
View(iwf_bigrams)
negation_words <- c("not", "no", "never", "without")
iwf_notwords <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, value, sort = TRUE)
iwf_bigrams <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% # this looks for a two word phrase
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
cbd_bigrams <- tidy(cbd_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
negation_words <- c("not", "no", "never", "without")
iwf_notwords <- tidy(iwf_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, value, sort = TRUE)
cbd_notwords <- tidy(cbd_corpus) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep=" ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
count(word2, value, sort = TRUE)
iwf_notwords %>%
mutate(contribution = n * value) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * value, fill = n * value > 0)) +
geom_col(show.legend = FALSE) +
xlab("Words preceded by \"not\"") +
ylab("Sentiment value * number of occurrences") +
coord_flip()
cbd_notwords %>%
mutate(contribution = n * value) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * value, fill = n * value > 0)) +
geom_col(show.legend = FALSE) +
xlab("Words preceded by \"not\"") +
ylab("Sentiment value * number of occurrences") +
coord_flip()
